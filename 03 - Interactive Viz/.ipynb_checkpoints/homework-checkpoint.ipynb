{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a choropleth map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import folium\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading & wrangling the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_path = 'data/P3_GrantExport.xlsx'\n",
    "grant_data = pd.read_excel(data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by selecting the features we're interested in. Obviously, we need the grant given to a project. We also want the University (from which we will retrieve the canton) and the Institution (since for some projects one is missing, but we're somehow confident we can retrieve the canton from either of those two). At last, we decide for now to save the reason a project got a funding, without being sure whether or not it will be usefull.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Approved Amount                 63967\n",
       "University                      50988\n",
       "Institution                     58831\n",
       "Funding Instrument Hierarchy    62915\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grant_data = grant_data[[\"Approved Amount\", \"University\", \"Institution\",\"Funding Instrument Hierarchy\"]]\n",
    "grant_data.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now we did not remove any entries. A more thorough visualization gave us the confirmation that we should though. We start by removing entries for which the Approved Amount is not a number, since we won't be able to use those data in this study."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Approved Amount                 52663\n",
       "University                      50487\n",
       "Institution                     48205\n",
       "Funding Instrument Hierarchy    51620\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grant_data = grant_data[grant_data['Approved Amount'].apply(lambda x: str(x).isdigit())]\n",
    "grant_data.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see we already removed about 11K entries, but we can do better. Indeed, we will use the Google's API to link a university name or an institution to a canton. So far we are confident that we can find the canton from either of those two. That means however, that we cannot treat data that miss both those values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Approved Amount                 51843\n",
       "University                      50487\n",
       "Institution                     48205\n",
       "Funding Instrument Hierarchy    50800\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grant_data = grant_data.dropna(subset=[\"Institution\", \"University\"], how=\"all\")\n",
    "grant_data.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We removed another 1K entries. But we saw a special value in the university field: Nicht zuteilbar - NA, for which we won't be able to retrieve the canton."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Approved Amount                 49252\n",
       "University                      47896\n",
       "Institution                     48025\n",
       "Funding Instrument Hierarchy    48231\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grant_data = grant_data[grant_data[\"University\"] != \"Nicht zuteilbar - NA\"]\n",
    "grant_data.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that for many entries, an acronym is given at the end of the University field. A first logical step to do before moving to an API is to retrieve this acronym, and when possible, associate it to a canton (sometimes, it is already the canton's abbreviation itself). We will then have to  use the API on the remaining, undetermined entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ZH                           6704\n",
       "GE                           6346\n",
       "ETHZ                         6093\n",
       "BE                           5422\n",
       "BS                           4685\n",
       "EPFL                         4370\n",
       "LA                           4062\n",
       "FR                           2041\n",
       "NE                           1580\n",
       "NPO                          1463\n",
       "nan                          1356\n",
       "PSI                           535\n",
       "FP                            490\n",
       "SG                            424\n",
       "USI                           338\n",
       "EAWAG                         330\n",
       "HES-SO                        270\n",
       "ZFH                           256\n",
       "EMPA                          236\n",
       "FHNW                          221\n",
       "WSL                           220\n",
       "LU                            211\n",
       "IHEID                         194\n",
       "BFH                           136\n",
       "AGS                           135\n",
       "SUPSI                         134\n",
       "FMI                            83\n",
       "ASPIT                          81\n",
       "IDIAP                          81\n",
       "HSLU                           61\n",
       "                             ... \n",
       "HEPL                           16\n",
       "IRO                            14\n",
       "PHLU                           14\n",
       "PHSG                           13\n",
       "PHBern                         12\n",
       "EHB                            12\n",
       "IKG                            12\n",
       "SPF                            10\n",
       "CREALP                          8\n",
       "BITG                            8\n",
       "HEPBEJUNE                       7\n",
       "HEPFR                           7\n",
       "PHZG                            7\n",
       "PHGR                            7\n",
       "RWS                             6\n",
       "PHTG                            6\n",
       "ISR                             6\n",
       "FUS                             6\n",
       "IRSOL                           5\n",
       "PHSZ                            5\n",
       "ISSKA                           3\n",
       "STHB                            3\n",
       "FHKD                            3\n",
       "FTL                             2\n",
       "SHLR                            2\n",
       "ASP                             2\n",
       "PHVS                            2\n",
       "FFHS                            1\n",
       "Forschungskommission SAGW       1\n",
       "PHSH                            1\n",
       "Name: short, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grant_data[\"short\"] = grant_data[\"University\"].apply(lambda x : str(x).split(\"- \")[-1])\n",
    "grant_data[\"short\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this trick we can already sort a large portion of the dataframe. We will now create a feature \"Canton\" which we can fill with values of \"Short\" we can associate for a canton (including EPFL and ETH in VD and ZH because, come on), and let blank for others. To get the list of canton acronyms, we use bash: \n",
    "\n",
    "\n",
    "\"grep -rnw ch-cantons.topojson.json -e '\"id\":' | awk '{print $3}' > cantons.csv\"\n",
    "\n",
    "And then we can compare the list of acronyms Folium will know with the list of acronyms we have.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#We already know the locations of some frequent occurences and it seems better to call the API on the fewer cases possible\n",
    "grant_data.replace([\"EPFL\", \"ETHZ\", \"LA\"], [\"VD\", \"ZH\", \"VD\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'cantons.csv' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-3a3de857b489>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0macronyms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cantons.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0macronyms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0macronyms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    643\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 645\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    647\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    386\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 388\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mchunksize\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    727\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    730\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m    920\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    921\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 922\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    923\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    924\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1387\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'allow_leading_cols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1389\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_parser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0;31m# XXX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/parser.pyx\u001b[0m in \u001b[0;36mpandas.parser.TextReader.__cinit__ (pandas/parser.c:4019)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/parser.pyx\u001b[0m in \u001b[0;36mpandas.parser.TextReader._setup_parser_source (pandas/parser.c:7967)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: File b'cantons.csv' does not exist"
     ]
    }
   ],
   "source": [
    "acronyms = pd.read_csv(\"cantons.csv\", header=None).dropna(axis=1)\n",
    "acronyms = acronyms[0].apply(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "grant_data[\"Canton\"] = grant_data[\"short\"][grant_data[\"short\"].isin(acronyms.values)]\n",
    "grant_data[\"Canton\"].value_counts()\n",
    "#grant_data[\"Canton\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's 40K less google searches ! :D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grant_data.to_csv(\"data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should finally be able to retrieve the canton feature in this dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Linking the University name to a Swiss canton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "geo_str = 'ch-cantons.topojson.json'\n",
    "\n",
    "ch_map = folium.Map(location=[46.6430788,8.018626], tiles='Mapbox Bright', zoom_start=7)\n",
    "ch_map.choropleth(geo_path=geo_str)\n",
    "ch_map.save('ch_map.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%HTML\n",
    "<iframe width='100%' height=\"350\" src=\"ch_map.html\"></iframe>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To parse the name in the University column, we define the function find_canton_abrv. This function takes a string with some clue about the location and then try to find the location from this clue using the geopy library. Then from the predicted geolocation we do a reverse geocoding using the library reverse_geocoder. Finally, we use the find the canton name and convert it to an abreviation using the file cantons.csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# library used to parse location\n",
    "from geopy.geocoders import Nominatim\n",
    "import reverse_geocoder as rg\n",
    "\n",
    "# data needed by parse_name_for_cantons\n",
    "abrv_path = 'data/cantons.csv'\n",
    "abrv_data = pd.read_csv(abrv_path, sep=',')\n",
    "abrv_data.set_index('canton', inplace=True)\n",
    "\n",
    "def find_canton_abrv(clue):\n",
    "    \"\"\"Find canton abreviation. \n",
    "    Take a string containg clues as input and\n",
    "    output a string of the abreviation or NaN if not found\"\"\"\n",
    "    \n",
    "    # find location from clue\n",
    "    geolocator = Nominatim()\n",
    "    location = geolocator.geocode(clue)\n",
    "    \n",
    "    if location != None:\n",
    "        # extract coordinates\n",
    "        coord = (location.latitude, location.longitude)\n",
    "    \n",
    "        # reverse geolocation\n",
    "        info = rg.search(coord)\n",
    "    \n",
    "        if info[0]['cc'] == 'CH':\n",
    "            canton = info[0]['admin1']\n",
    "            return abrv_data.loc[canton][0]\n",
    "    \n",
    "    else:\n",
    "        return 'NaN'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Approved Amount</th>\n",
       "      <th>University</th>\n",
       "      <th>Institution</th>\n",
       "      <th>Funding Instrument Hierarchy</th>\n",
       "      <th>short</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>41022</td>\n",
       "      <td>Université de Genève - GE</td>\n",
       "      <td>Faculté de Psychologie et des Sciences de l'Ed...</td>\n",
       "      <td>Project funding</td>\n",
       "      <td>GE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>79732</td>\n",
       "      <td>NPO (Biblioth., Museen, Verwalt.) - NPO</td>\n",
       "      <td>Kommission für das Corpus philosophorum medii ...</td>\n",
       "      <td>Project funding</td>\n",
       "      <td>NPO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>52627</td>\n",
       "      <td>Universität Basel - BS</td>\n",
       "      <td>Abt. Handschriften und Alte Drucke Bibliothek ...</td>\n",
       "      <td>Project funding</td>\n",
       "      <td>BS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>120042</td>\n",
       "      <td>NPO (Biblioth., Museen, Verwalt.) - NPO</td>\n",
       "      <td>Schweiz. Thesauruskommission</td>\n",
       "      <td>Project funding</td>\n",
       "      <td>NPO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>53009</td>\n",
       "      <td>Université de Fribourg - FR</td>\n",
       "      <td>Séminaire de politique économique, d'économie ...</td>\n",
       "      <td>Project funding</td>\n",
       "      <td>FR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Approved Amount                               University  \\\n",
       "1            41022                Université de Genève - GE   \n",
       "2            79732  NPO (Biblioth., Museen, Verwalt.) - NPO   \n",
       "3            52627                   Universität Basel - BS   \n",
       "4           120042  NPO (Biblioth., Museen, Verwalt.) - NPO   \n",
       "5            53009              Université de Fribourg - FR   \n",
       "\n",
       "                                         Institution  \\\n",
       "1  Faculté de Psychologie et des Sciences de l'Ed...   \n",
       "2  Kommission für das Corpus philosophorum medii ...   \n",
       "3  Abt. Handschriften und Alte Drucke Bibliothek ...   \n",
       "4                       Schweiz. Thesauruskommission   \n",
       "5  Séminaire de politique économique, d'économie ...   \n",
       "\n",
       "  Funding Instrument Hierarchy short  \n",
       "1              Project funding    GE  \n",
       "2              Project funding   NPO  \n",
       "3              Project funding    BS  \n",
       "4              Project funding   NPO  \n",
       "5              Project funding    FR  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grant_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
